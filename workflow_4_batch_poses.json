{
  "67": {
    "inputs": {
      "unet_name": "qwen_image_edit_2509_bf16.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "69": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "74": {
    "inputs": {
      "seed": 794829004061081,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "denoise": 0.97,
      "model": [
        "161",
        0
      ],
      "positive": [
        "163",
        0
      ],
      "negative": [
        "164",
        0
      ],
      "latent_image": [
        "178",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "76": {
    "inputs": {
      "samples": [
        "74",
        0
      ],
      "vae": [
        "69",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "88": {
    "inputs": {
      "PowerLoraLoaderHeaderWidget": {
        "type": "PowerLoraLoaderHeaderWidget"
      },
      "lora_1": {
        "on": true,
        "lora": "Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
        "strength": 1
      },
      "âž• Add Lora": "",
      "model": [
        "67",
        0
      ],
      "clip": [
        "160",
        0
      ]
    },
    "class_type": "Power Lora Loader (rgthree)",
    "_meta": {
      "title": "Power Lora Loader (rgthree)"
    }
  },
  "94": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "76",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "160": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "161": {
    "inputs": {
      "strength": 1,
      "model": [
        "162",
        0
      ]
    },
    "class_type": "CFGNorm",
    "_meta": {
      "title": "CFGNorm"
    }
  },
  "162": {
    "inputs": {
      "shift": 3,
      "model": [
        "88",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "163": {
    "inputs": {
      "prompt": "the woman in image 1 has the pose in image 2. nude nail color",
      "clip": [
        "88",
        1
      ],
      "vae": [
        "69",
        0
      ],
      "image1": [
        "176",
        0
      ],
      "image2": [
        "189",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "164": {
    "inputs": {
      "prompt": "",
      "clip": [
        "88",
        1
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "169": {
    "inputs": {
      "unet_name": "flux1-kontext-dev-Q5_1.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "176": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1.1,
      "resolution_steps": 1,
      "image": [
        "200",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "178": {
    "inputs": {
      "pixels": [
        "176",
        0
      ],
      "vae": [
        "69",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "189": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1.1,
      "resolution_steps": 1,
      "image": [
        "198",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "195": {
    "inputs": {
      "images": [
        "189",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "198": {
    "inputs": {
      "directory": [
        "199",
        0
      ],
      "image_load_cap": 0,
      "start_index": 0,
      "load_always": false,
      "sort_method": "None"
    },
    "class_type": "LoadImageListFromDir //Inspire",
    "_meta": {
      "title": "Load Image List From Dir (Inspire)"
    }
  },
  "199": {
    "inputs": {
      "value": "F:\\youtube\\OpenPose Qwen edit plus\\pose images"
    },
    "class_type": "easy string",
    "_meta": {
      "title": "Input Images Folder path for example : F:\\images\\clara\\paris-photos"
    }
  },
  "200": {
    "inputs": {
      "image": "openart-image_13Xpod0U_1759752532501_raw.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Image 1 (Model image)"
    }
  },
  "201": {
    "inputs": {
      "images": [
        "189",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}